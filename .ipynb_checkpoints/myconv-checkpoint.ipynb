{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ddd1dc-88c1-4dec-b8ab-81afee73a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#二维卷积无padding\n",
    "def corr2d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),Stride=(1,1))\n",
    "#二维卷积有padding\n",
    "#def corr2d_pad(Data=(a,b),Kernel=(c,d),Padding=(e,f),Stride=(g,h)):\n",
    "def corr2d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d_pad(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),(1,1),(1,1))\n",
    "#三维卷积无padding\n",
    "def corr3d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Stride=(1,1,1))\n",
    "#三维卷积有padding\n",
    "def corr3d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Padding=(0,0,0),Stride=(1,1,1))\n",
    "####################################################\n",
    "#池化\n",
    "#二维池化无padding\n",
    "#def pool2d(Data,Mode='max,'avg'):\n",
    "def pool2d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d(torch.tensor([[1.,2,3],[4,5,6],[5,6,7.]]),(2,3),'mean',Stride=(1,1))\n",
    "#二维池化有padding\n",
    "def pool2d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d_pad(torch.tensor([[1.,2,3],[4,5,6],[5,6,7]]),(2,2),'mean',(1,1),(1,1))\n",
    "#三维池化无padding\n",
    "def pool3d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Stride=(1,1,1))\n",
    "#三维池化有padding\n",
    "def pool3d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Padding=(0,0,0),Stride=(1,1,1))\n",
    "#二维测试\n",
    "#Data=torch.randn(5,5)\n",
    "#Kernel=torch.randn(3,3)\n",
    "#Stride=(1,1)\n",
    "#Padding=(1,1)\n",
    "#print(Data,Kernel,Stride)\n",
    "#print((Data[1:4,1:4]*Kernel).sum())\n",
    "#Y=corr2d_pad(Data,Kernel,Stride,Padding)\n",
    "#print(Y)\n",
    "#Z=pool2d_pad(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#三维测试\n",
    "#Data=torch.randn(5,5,5)\n",
    "#Kernel=torch.randn(3,3,3)\n",
    "#Stride=(1,1,1)\n",
    "#Padding=(1,1,1)\n",
    "#print(Data,Kernel,Padding,Stride)\n",
    "#print((Data[1:4,1:4,2:5]*Kernel).sum())\n",
    "#Y=corr3d_pad(Data=Data,Kernel=Kernel,Padding=Padding,Stride=Stride)\n",
    "#print(Y)\n",
    "#Z=pool3d_pad(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6354d59f-ac5c-43f3-8be3-bef7440cf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积层操作无padding\n",
    "#下面是二维样本特征时多样本多输出的卷积层\n",
    "def convnet_2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1))\n",
    "    #第几个样本\n",
    "    for i in range(Y.shape[0]):\n",
    "        #第几个输出内核\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr2d_pad(Data[i,:,:].reshape(Data.shape[1:]),Kernel[j,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:]+=bias[j]        \n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#定义完整的二维样本卷积层\n",
    "#def conv_2d(Data=(样本数,输入通道数,特征),Kernel=(输出通道数,输入通道数,二维卷积核),bias=(输出通道数,1),Padding=(二维扩充尺寸),Stride=(二维步进尺寸))->(样本数,输出通道数,卷积结果)\n",
    "def convnet2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[2]-Kernel.shape[2]+2*Padding[0])//Stride[0]+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[1])//Stride[1]+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),(0,Padding[0],Padding[1]),(1,Stride[0],Stride[1])).reshape(Y.shape[2],Y.shape[3])\n",
    "            Y[i,j,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#每个(输出通道,输入通道)组合都有一个偏置还是每个输出通道才有偏置，还是每个输入通道有偏置？还是每个卷积核都有一个偏置？\n",
    "#前面的输出矩阵的尺寸容易理解，找几个例子推算一下就清楚了，\n",
    "#下面是三维样本特征时多样本多输出的卷积层\n",
    "def convnet_3d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#下面是二维样本特征多样本多输出的汇聚层。\n",
    "def poolnet_2d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=pool2d_pad(Data[i,j,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_2d(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#下面是三维样本特征多样本多输出的汇聚层\n",
    "def poolnet_3d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1,(Data.shape[4]-Kernel[2]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=pool3d_pad(Data[i,j,:,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_3d(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df657407-632f-4e5c-8c08-0bb868618191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def convnet_2d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_2d(Data,Kernel,mode,Padding,Stride)\n",
    "#def convnet_3d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_3d(Data,Kernel,mode,Padding,Stride)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "torch.manual_seed(1)\n",
    "Data1=torch.randn((20,1,28,28))\n",
    "Label1=1/(1+torch.exp(-torch.randn((20,10))))\n",
    "lr=0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec315fe-4c4e-4739-8ba8-7d4b504984e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kernel1=torch.randn((6,1,5,5),requires_grad=True)\n",
    "bias1=torch.randn((Kernel1.shape[0],1),requires_grad=True)\n",
    "Padding1=(2,2)\n",
    "Stride1=(1,1)\n",
    "Kernel2=torch.randn((16,6,5,5),requires_grad=True)\n",
    "bias2=torch.randn((Kernel2.shape[0],1),requires_grad=True)\n",
    "weight1=torch.randn((400,120),requires_grad=True)\n",
    "weight2=torch.randn((120,84),requires_grad=True)\n",
    "weight3=torch.randn((84,10),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa659c3c-cb74-41c6-b4b1-31d75c5f98df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n",
      "tensor(0.3429, grad_fn=<MulBackward0>) tensor([1.0000, 0.9835, 0.9908, 0.9998, 0.9998, 0.9989, 0.9996, 0.9975, 0.9985,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n",
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n",
      "tensor(0.2856, grad_fn=<MulBackward0>) tensor([1.0000, 0.9854, 0.9927, 0.9998, 0.9998, 0.9990, 0.9997, 0.9976, 0.9987,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n",
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n",
      "tensor(0.2478, grad_fn=<MulBackward0>) tensor([1.0000, 0.9866, 0.9938, 0.9998, 0.9998, 0.9990, 0.9997, 0.9978, 0.9988,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n",
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n",
      "tensor(0.2205, grad_fn=<MulBackward0>) tensor([1.0000, 0.9876, 0.9945, 0.9998, 0.9998, 0.9991, 0.9997, 0.9979, 0.9989,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n",
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n",
      "tensor(0.1998, grad_fn=<MulBackward0>) tensor([1.0000, 0.9883, 0.9951, 0.9998, 0.9998, 0.9991, 0.9998, 0.9980, 0.9990,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n",
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n",
      "tensor(0.1834, grad_fn=<MulBackward0>) tensor([1.0000, 0.9889, 0.9955, 0.9998, 0.9998, 0.9991, 0.9998, 0.9981, 0.9991,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n",
      "torch.Size([20, 6, 28, 28])\n",
      "torch.Size([20, 6, 14, 14])\n",
      "torch.Size([20, 16, 10, 10])\n",
      "torch.Size([20, 16, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#上面输出的是全链接层的结果\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#我们思考一下损失函数怎么定义，从结果上来看是概率分布的交叉熵，从实际上来看应该是最大似然函数。\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m(Label1\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlog(Y3))\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m Kernel1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39mKernel1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m-\u001b[39mlr\u001b[38;5;241m*\u001b[39mKernel1\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     21\u001b[0m bias1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39mbias1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m-\u001b[39mlr\u001b[38;5;241m*\u001b[39mbias1\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for tt in range(30):\n",
    "    C1=convnet2d(Data=Data1,Kernel=Kernel1,bias=bias1,Padding=Padding1,Stride=Stride1)\n",
    "    print(C1.shape)\n",
    "    P1=poolnet_2d(C1,Kernel=(2,2),mode='mean',Padding=(0,0),Stride=(2,2))\n",
    "    print(P1.shape)\n",
    "    C2=convnet2d(P1,Kernel2,bias2,Padding=(0,0),Stride=(1,1))\n",
    "    print(C2.shape)\n",
    "    P2=poolnet_2d(C2,Kernel=(2,2),mode='mean',Padding=(0,0),Stride=(2,2))\n",
    "    print(P2.shape)\n",
    "    Y=torch.zeros((P2.shape[0],P2.shape[1]*P2.shape[2]*P2.shape[3]))\n",
    "    for i in range(P2.shape[0]):\n",
    "        Y[i,:]=P2[i,:,:,:].reshape(1,-1)\n",
    "    Y1=1/(1+torch.exp(-torch.mm(Y,weight1)))\n",
    "    Y2=1/(1+torch.exp(-torch.mm(Y1,weight2)))\n",
    "    Y3=1/(1+torch.exp(-torch.mm(Y2,weight3)))\n",
    "    #上面输出的是全链接层的结果\n",
    "    #我们思考一下损失函数怎么定义，从结果上来看是概率分布的交叉熵，从实际上来看应该是最大似然函数。\n",
    "    loss=-1*(Label1*torch.log(Y3)).sum()\n",
    "    loss.backward()\n",
    "    Kernel1.data=Kernel1.data-lr*Kernel1.grad.data\n",
    "    bias1.data=bias1.data-lr*bias1.grad.data\n",
    "    Kernel2.data=Kernel2.data-lr*Kernel2.grad.data\n",
    "    bias2.data=bias2.data-lr*bias2.grad.data\n",
    "    weight1.data=weight1.data-lr*weight1.grad.data\n",
    "    weight2.data=weight2.data-lr*weight2.grad.data\n",
    "    weight3.data=weight3.data-lr*weight3.grad.data\n",
    "    Kernel1.grad.data.zero_()\n",
    "    bias1.grad.data.zero_()\n",
    "    Kernel2.grad.data.zero_()\n",
    "    bias2.grad.data.zero_()\n",
    "    weight1.grad.data.zero_()\n",
    "    weight2.grad.data.zero_()\n",
    "    weight3.grad.data.zero_()\n",
    "    print(loss,Y3[0,:],Label1[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6edc0097-a303-452f-bf85-06c9fbad771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4451, grad_fn=<MulBackward0>) tensor([1.0000, 0.9804, 0.9871, 0.9998, 0.9998, 0.9989, 0.9995, 0.9972, 0.9982,\n",
      "        1.0000], grad_fn=<SliceBackward0>) tensor([0.3466, 0.3445, 0.3448, 0.1904, 0.6094, 0.3527, 0.2917, 0.2792, 0.4991,\n",
      "        0.3871])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "390bae47-bb89-4be9-9486-6245e4300ab0",
   "metadata": {},
   "source": [
    "# backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad4425-1e43-40b9-aaca-35a24c9a967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#二维卷积无padding\n",
    "def corr2d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),Stride=(1,1))\n",
    "#二维卷积有padding\n",
    "#def corr2d_pad(Data=(a,b),Kernel=(c,d),Padding=(e,f),Stride=(g,h)):\n",
    "def corr2d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d_pad(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),(1,1),(1,1))\n",
    "#三维卷积无padding\n",
    "def corr3d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Stride=(1,1,1))\n",
    "#三维卷积有padding\n",
    "def corr3d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Padding=(0,0,0),Stride=(1,1,1))\n",
    "####################################################\n",
    "#池化\n",
    "#二维池化无padding\n",
    "#def pool2d(Data,Mode='max,'avg'):\n",
    "def pool2d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d(torch.tensor([[1.,2,3],[4,5,6],[5,6,7.]]),(2,3),'mean',Stride=(1,1))\n",
    "#二维池化有padding\n",
    "def pool2d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d_pad(torch.tensor([[1.,2,3],[4,5,6],[5,6,7]]),(2,2),'mean',(1,1),(1,1))\n",
    "#三维池化无padding\n",
    "def pool3d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Stride=(1,1,1))\n",
    "#三维池化有padding\n",
    "def pool3d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Padding=(0,0,0),Stride=(1,1,1))\n",
    "#二维测试\n",
    "#Data=torch.randn(5,5)\n",
    "#Kernel=torch.randn(3,3)\n",
    "#Stride=(1,1)\n",
    "#Padding=(1,1)\n",
    "#print(Data,Kernel,Stride)\n",
    "#print((Data[1:4,1:4]*Kernel).sum())\n",
    "#Y=corr2d_pad(Data,Kernel,Stride,Padding)\n",
    "#print(Y)\n",
    "#Z=pool2d_pad(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#三维测试\n",
    "#Data=torch.randn(5,5,5)\n",
    "#Kernel=torch.randn(3,3,3)\n",
    "#Stride=(1,1,1)\n",
    "#Padding=(1,1,1)\n",
    "#print(Data,Kernel,Padding,Stride)\n",
    "#print((Data[1:4,1:4,2:5]*Kernel).sum())\n",
    "#Y=corr3d_pad(Data=Data,Kernel=Kernel,Padding=Padding,Stride=Stride)\n",
    "#print(Y)\n",
    "#Z=pool3d_pad(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53579a2b-4c8b-4f91-90f3-711fd720af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积层操作无padding\n",
    "#下面是二维样本特征时多样本多输出的卷积层\n",
    "def convnet_2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1))\n",
    "    #第几个样本\n",
    "    for i in range(Y.shape[0]):\n",
    "        #第几个输出内核\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr2d_pad(Data[i,:,:].reshape(Data.shape[1:]),Kernel[j,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:]+=bias[j]        \n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#定义完整的二维样本卷积层\n",
    "#def conv_2d(Data=(样本数,输入通道数,特征),Kernel=(输出通道数,输入通道数,二维卷积核),bias=(输出通道数,1),Padding=(二维扩充尺寸),Stride=(二维步进尺寸))->(样本数,输出通道数,卷积结果)\n",
    "def convnet2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[2]-Kernel.shape[2]+2*Padding[0])//Stride[0]+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[1])//Stride[1]+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),(0,Padding[0],Padding[1]),(1,Stride[0],Stride[1])).reshape(Y.shape[2],Y.shape[3])\n",
    "            Y[i,j,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#每个(输出通道,输入通道)组合都有一个偏置还是每个输出通道才有偏置，还是每个输入通道有偏置？还是每个卷积核都有一个偏置？\n",
    "#前面的输出矩阵的尺寸容易理解，找几个例子推算一下就清楚了，\n",
    "#下面是三维样本特征时多样本多输出的卷积层\n",
    "def convnet_3d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#下面是二维样本特征多样本多输出的汇聚层。\n",
    "def poolnet_2d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=pool2d_pad(Data[i,j,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_2d(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#下面是三维样本特征多样本多输出的汇聚层\n",
    "def poolnet_3d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1,(Data.shape[4]-Kernel[2]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=pool3d_pad(Data[i,j,:,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_3d(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aeebec-3b02-4631-93ad-bf31f662d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def convnet_2d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_2d(Data,Kernel,mode,Padding,Stride)\n",
    "#def convnet_3d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_3d(Data,Kernel,mode,Padding,Stride)\n",
    "Data1=torch.randn((4,28,28))\n",
    "Kernel1=torch.randn((6,5,5),requires_grad=True)\n",
    "bias1=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "Padding1=(2,2)\n",
    "Stride1=(1,1)\n",
    "C1=convnet_2d(Data=Data1,Kernel=Kernel1,bias=bias1,Padding=Padding1,Stride=Stride1)\n",
    "print(C1.shape)\n",
    "P1=poolnet_2d(C1,Kernel=(2,2),mode='mean',Padding=(0,0),Stride=(2,2))\n",
    "print(P1.shape)\n",
    "Kernel2=torch.randn((16,6,5,5),requires_grad=True)\n",
    "bias2=torch.randn((Kernel2.shape[0],1),requires_grad=True)\n",
    "C2=convnet_3d(P1,Kernel2,bias2,Padding=(0,0,0),Stride=(1,1,1))\n",
    "print(C2.shape)\n",
    "P2=poolnet_3d(C2,Kernel=(1,2,2),mode='mean',Padding=(0,0,0),Stride=(2,2,2))\n",
    "print(P2.shape)\n",
    "Y=torch.zeros((P2.shape[0],P2.shape[1]*P2.shape[2]*P2.shape[3]*P2.shape[4]))\n",
    "for i in range(P2.shape[0]):\n",
    "    Y[i,:]=P2[i,:,:,:,:].reshape(1,-1)\n",
    "\n",
    "weight1=torch.randn((Y.shape[1],120),requires_grad=True)\n",
    "Y1=1/(1+torch.exp(-torch.mm(Y,weight1)))\n",
    "weight2=torch.randn((Y1.shape[1],84),requires_grad=True)\n",
    "Y2=1/(1+torch.exp(-torch.mm(Y1,weight2)))\n",
    "weight3=torch.randn((Y2.shape[1],10),requires_grad=True)\n",
    "Y3=1/(1+torch.exp(-torch.mm(Y2,weight3)))\n",
    "print(Y3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

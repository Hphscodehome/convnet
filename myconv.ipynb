{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ddd1dc-88c1-4dec-b8ab-81afee73a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#二维卷积无padding\n",
    "def corr2d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),Stride=(1,1))\n",
    "#二维卷积有padding\n",
    "#def corr2d_pad(Data=(a,b),Kernel=(c,d),Padding=(e,f),Stride=(g,h)):\n",
    "def corr2d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d_pad(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),(1,1),(1,1))\n",
    "#三维卷积无padding\n",
    "def corr3d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Stride=(1,1,1))\n",
    "#三维卷积有padding\n",
    "def corr3d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Padding=(0,0,0),Stride=(1,1,1))\n",
    "####################################################\n",
    "#池化\n",
    "#二维池化无padding\n",
    "#def pool2d(Data,Mode='max,'avg'):\n",
    "def pool2d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d(torch.tensor([[1.,2,3],[4,5,6],[5,6,7.]]),(2,3),'mean',Stride=(1,1))\n",
    "#二维池化有padding\n",
    "def pool2d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d_pad(torch.tensor([[1.,2,3],[4,5,6],[5,6,7]]),(2,2),'mean',(1,1),(1,1))\n",
    "#三维池化无padding\n",
    "def pool3d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Stride=(1,1,1))\n",
    "#三维池化有padding\n",
    "def pool3d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Padding=(0,0,0),Stride=(1,1,1))\n",
    "#二维测试\n",
    "#Data=torch.randn(5,5)\n",
    "#Kernel=torch.randn(3,3)\n",
    "#Stride=(1,1)\n",
    "#Padding=(1,1)\n",
    "#print(Data,Kernel,Stride)\n",
    "#print((Data[1:4,1:4]*Kernel).sum())\n",
    "#Y=corr2d_pad(Data,Kernel,Stride,Padding)\n",
    "#print(Y)\n",
    "#Z=pool2d_pad(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#三维测试\n",
    "#Data=torch.randn(5,5,5)\n",
    "#Kernel=torch.randn(3,3,3)\n",
    "#Stride=(1,1,1)\n",
    "#Padding=(1,1,1)\n",
    "#print(Data,Kernel,Padding,Stride)\n",
    "#print((Data[1:4,1:4,2:5]*Kernel).sum())\n",
    "#Y=corr3d_pad(Data=Data,Kernel=Kernel,Padding=Padding,Stride=Stride)\n",
    "#print(Y)\n",
    "#Z=pool3d_pad(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6354d59f-ac5c-43f3-8be3-bef7440cf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积层操作无padding\n",
    "#下面是二维样本特征时多样本多输出的卷积层\n",
    "def convnet_2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1))\n",
    "    #第几个样本\n",
    "    for i in range(Y.shape[0]):\n",
    "        #第几个输出内核\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr2d_pad(Data[i,:,:].reshape(Data.shape[1:]),Kernel[j,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:]+=bias[j]        \n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#定义完整的二维样本卷积层\n",
    "#def conv_2d(Data=(样本数,输入通道数,特征),Kernel=(输出通道数,输入通道数,二维卷积核),bias=(输出通道数,1),Padding=(二维扩充尺寸),Stride=(二维步进尺寸))->(样本数,输出通道数,卷积结果)\n",
    "def convnet2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[2]-Kernel.shape[2]+2*Padding[0])//Stride[0]+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[1])//Stride[1]+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),(0,Padding[0],Padding[1]),(1,Stride[0],Stride[1])).reshape(Y.shape[2],Y.shape[3])\n",
    "            Y[i,j,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#每个(输出通道,输入通道)组合都有一个偏置还是每个输出通道才有偏置，还是每个输入通道有偏置？还是每个卷积核都有一个偏置？\n",
    "#前面的输出矩阵的尺寸容易理解，找几个例子推算一下就清楚了，\n",
    "#下面是三维样本特征时多样本多输出的卷积层\n",
    "def convnet_3d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#下面是二维样本特征多样本多输出的汇聚层。\n",
    "def poolnet_2d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=pool2d_pad(Data[i,j,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_2d(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#下面是三维样本特征多样本多输出的汇聚层\n",
    "def poolnet_3d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1,(Data.shape[4]-Kernel[2]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=pool3d_pad(Data[i,j,:,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_3d(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df657407-632f-4e5c-8c08-0bb868618191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def convnet_2d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_2d(Data,Kernel,mode,Padding,Stride)\n",
    "#def convnet_3d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_3d(Data,Kernel,mode,Padding,Stride)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "torch.manual_seed(1)\n",
    "Data1=torch.randn((10,1,28,28))\n",
    "label=torch.randn((10,10))\n",
    "Label1=torch.exp(label)/torch.exp(label).sum(axis=1).reshape(10,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f326732-e921-4252-a9d6-62557f4094a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "         0.0995],\n",
      "        [0.0717, 0.1649, 0.2175, 0.0514, 0.0129, 0.1458, 0.0254, 0.2547, 0.0264,\n",
      "         0.0293],\n",
      "        [0.2208, 0.0468, 0.0673, 0.0594, 0.1954, 0.0363, 0.0760, 0.1210, 0.0861,\n",
      "         0.0909],\n",
      "        [0.1221, 0.0573, 0.0587, 0.1118, 0.1704, 0.0321, 0.1017, 0.1623, 0.1658,\n",
      "         0.0176],\n",
      "        [0.1522, 0.4274, 0.0409, 0.0095, 0.1310, 0.0239, 0.1097, 0.0138, 0.0089,\n",
      "         0.0826],\n",
      "        [0.0100, 0.0450, 0.1766, 0.0717, 0.2350, 0.0751, 0.0098, 0.0189, 0.1788,\n",
      "         0.1792],\n",
      "        [0.1464, 0.0368, 0.4047, 0.0598, 0.0956, 0.0731, 0.0193, 0.0765, 0.0165,\n",
      "         0.0713],\n",
      "        [0.0310, 0.1438, 0.2350, 0.0475, 0.0858, 0.1226, 0.0202, 0.0540, 0.0971,\n",
      "         0.1631],\n",
      "        [0.3520, 0.0491, 0.0726, 0.1224, 0.0558, 0.0451, 0.0432, 0.0560, 0.0500,\n",
      "         0.1538],\n",
      "        [0.1674, 0.0415, 0.0745, 0.3021, 0.0388, 0.0509, 0.1673, 0.0410, 0.1065,\n",
      "         0.0100]])\n"
     ]
    }
   ],
   "source": [
    "print(Label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec315fe-4c4e-4739-8ba8-7d4b504984e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kernel1=torch.randn((6,1,5,5),requires_grad=True)\n",
    "bias1=torch.randn((Kernel1.shape[0],1),requires_grad=True)\n",
    "Padding1=(2,2)\n",
    "Stride1=(1,1)\n",
    "Kernel2=torch.randn((16,6,5,5),requires_grad=True)\n",
    "bias2=torch.randn((Kernel2.shape[0],1),requires_grad=True)\n",
    "weight1=torch.randn((400,120),requires_grad=True)\n",
    "weight2=torch.randn((120,84),requires_grad=True)\n",
    "weight3=torch.randn((84,10),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa659c3c-cb74-41c6-b4b1-31d75c5f98df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.1017, 0.1003, 0.0730, 0.0469, 0.2351, 0.0850, 0.0607, 0.0697, 0.1363,\n",
      "        0.0912], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1822, grad_fn=<SumBackward0>) tensor([0.1017, 0.1003, 0.0730, 0.0469, 0.2351, 0.0850, 0.0607, 0.0697, 0.1363,\n",
      "        0.0912], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0749, 0.0909, 0.0762, 0.0461, 0.2593, 0.0941, 0.0488, 0.0750, 0.1529,\n",
      "        0.0819], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1836, grad_fn=<SumBackward0>) tensor([0.0749, 0.0909, 0.0762, 0.0461, 0.2593, 0.0941, 0.0488, 0.0750, 0.1529,\n",
      "        0.0819], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0871, 0.0955, 0.0747, 0.0465, 0.2478, 0.0898, 0.0544, 0.0725, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1595, grad_fn=<SumBackward0>) tensor([0.0871, 0.0955, 0.0747, 0.0465, 0.2478, 0.0898, 0.0544, 0.0725, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0878, 0.0957, 0.0746, 0.0465, 0.2473, 0.0896, 0.0546, 0.0723, 0.1448,\n",
      "        0.0867], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1593, grad_fn=<SumBackward0>) tensor([0.0878, 0.0957, 0.0746, 0.0465, 0.2473, 0.0896, 0.0546, 0.0723, 0.1448,\n",
      "        0.0867], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0879, 0.0957, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1448,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1590, grad_fn=<SumBackward0>) tensor([0.0879, 0.0957, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1448,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0879, 0.0956, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1449,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1588, grad_fn=<SumBackward0>) tensor([0.0879, 0.0956, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1449,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0956, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1449,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1586, grad_fn=<SumBackward0>) tensor([0.0880, 0.0956, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1449,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0956, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1584, grad_fn=<SumBackward0>) tensor([0.0880, 0.0956, 0.0746, 0.0465, 0.2473, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0956, 0.0746, 0.0465, 0.2472, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1582, grad_fn=<SumBackward0>) tensor([0.0880, 0.0956, 0.0746, 0.0465, 0.2472, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0956, 0.0745, 0.0464, 0.2472, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1580, grad_fn=<SumBackward0>) tensor([0.0880, 0.0956, 0.0745, 0.0464, 0.2472, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1577, grad_fn=<SumBackward0>) tensor([0.0880, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0546, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1575, grad_fn=<SumBackward0>) tensor([0.0881, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1573, grad_fn=<SumBackward0>) tensor([0.0881, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1450,\n",
      "        0.0866], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1450,\n",
      "        0.0867], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1571, grad_fn=<SumBackward0>) tensor([0.0881, 0.0955, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1450,\n",
      "        0.0867], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1569, grad_fn=<SumBackward0>) tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2472, 0.0897, 0.0547, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2471, 0.0897, 0.0547, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1567, grad_fn=<SumBackward0>) tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2471, 0.0897, 0.0547, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2471, 0.0897, 0.0547, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1565, grad_fn=<SumBackward0>) tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2471, 0.0897, 0.0547, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1563, grad_fn=<SumBackward0>) tensor([0.0881, 0.0954, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0867], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1561, grad_fn=<SumBackward0>) tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1559, grad_fn=<SumBackward0>) tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1556, grad_fn=<SumBackward0>) tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1554, grad_fn=<SumBackward0>) tensor([0.0881, 0.0953, 0.0745, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1552, grad_fn=<SumBackward0>) tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2471, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0868], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2470, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0869], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1550, grad_fn=<SumBackward0>) tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2470, 0.0897, 0.0548, 0.0723, 0.1451,\n",
      "        0.0869], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0723, 0.1451,\n",
      "        0.0869], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1548, grad_fn=<SumBackward0>) tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0723, 0.1451,\n",
      "        0.0869], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0869], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1546, grad_fn=<SumBackward0>) tensor([0.0881, 0.0952, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0869], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0869], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1544, grad_fn=<SumBackward0>) tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0869], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1542, grad_fn=<SumBackward0>) tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1540, grad_fn=<SumBackward0>) tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1538, grad_fn=<SumBackward0>) tensor([0.0881, 0.0951, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1536, grad_fn=<SumBackward0>) tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0897, 0.0549, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1534, grad_fn=<SumBackward0>) tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0870], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0871], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1532, grad_fn=<SumBackward0>) tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0871], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0871], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1530, grad_fn=<SumBackward0>) tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2470, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0871], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0871], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1528, grad_fn=<SumBackward0>) tensor([0.0881, 0.0950, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1452,\n",
      "        0.0871], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0871], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1526, grad_fn=<SumBackward0>) tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0871], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0871], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1524, grad_fn=<SumBackward0>) tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0871], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1522, grad_fn=<SumBackward0>) tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1520, grad_fn=<SumBackward0>) tensor([0.0881, 0.0949, 0.0744, 0.0464, 0.2469, 0.0896, 0.0550, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0948, 0.0744, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1518, grad_fn=<SumBackward0>) tensor([0.0881, 0.0948, 0.0744, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0948, 0.0744, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1516, grad_fn=<SumBackward0>) tensor([0.0881, 0.0948, 0.0744, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0881, 0.0948, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1514, grad_fn=<SumBackward0>) tensor([0.0881, 0.0948, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0948, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1512, grad_fn=<SumBackward0>) tensor([0.0880, 0.0948, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0872], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0948, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0873], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1510, grad_fn=<SumBackward0>) tensor([0.0880, 0.0948, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1453,\n",
      "        0.0873], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1509, grad_fn=<SumBackward0>) tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1507, grad_fn=<SumBackward0>) tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1505, grad_fn=<SumBackward0>) tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2469, 0.0896, 0.0551, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1503, grad_fn=<SumBackward0>) tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0873], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1501, grad_fn=<SumBackward0>) tensor([0.0880, 0.0947, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1499, grad_fn=<SumBackward0>) tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1497, grad_fn=<SumBackward0>) tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1495, grad_fn=<SumBackward0>) tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1493, grad_fn=<SumBackward0>) tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1454,\n",
      "        0.0874], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1455,\n",
      "        0.0874], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1491, grad_fn=<SumBackward0>) tensor([0.0880, 0.0946, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1455,\n",
      "        0.0874], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1489, grad_fn=<SumBackward0>) tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0552, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1487, grad_fn=<SumBackward0>) tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1486, grad_fn=<SumBackward0>) tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1484, grad_fn=<SumBackward0>) tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1482, grad_fn=<SumBackward0>) tensor([0.0880, 0.0945, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0944, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1480, grad_fn=<SumBackward0>) tensor([0.0880, 0.0944, 0.0743, 0.0464, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0875], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0944, 0.0743, 0.0463, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0876], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1478, grad_fn=<SumBackward0>) tensor([0.0880, 0.0944, 0.0743, 0.0463, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0876], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n",
      "torch.Size([10, 6, 14, 14])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 16, 5, 5])\n",
      "tensor([0.0880, 0.0944, 0.0743, 0.0463, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0876], grad_fn=<SliceBackward0>)\n",
      "tensor(20.1476, grad_fn=<SumBackward0>) tensor([0.0880, 0.0944, 0.0743, 0.0463, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "        0.0876], grad_fn=<SliceBackward0>) tensor([0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "        0.0995])\n",
      "torch.Size([10, 6, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m C1\u001b[38;5;241m=\u001b[39mconvnet2d(Data\u001b[38;5;241m=\u001b[39mData1,Kernel\u001b[38;5;241m=\u001b[39mKernel1,bias\u001b[38;5;241m=\u001b[39mbias1,Padding\u001b[38;5;241m=\u001b[39mPadding1,Stride\u001b[38;5;241m=\u001b[39mStride1)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(C1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m P1\u001b[38;5;241m=\u001b[39m\u001b[43mpoolnet_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mPadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mStride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(P1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m C2\u001b[38;5;241m=\u001b[39mconvnet2d(P1,Kernel2,bias2,Padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),Stride\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m, in \u001b[0;36mpoolnet_2d\u001b[0;34m(Data, Kernel, mode, Padding, Stride)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 47\u001b[0m         Y[i,j,:,:]\u001b[38;5;241m=\u001b[39m\u001b[43mpool2d_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mData\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43mStride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "Cell \u001b[0;32mIn[3], line 71\u001b[0m, in \u001b[0;36mpool2d_pad\u001b[0;34m(Data, Kernel, mode, Padding, Stride)\u001b[0m\n\u001b[1;32m     69\u001b[0m             Y[i,j]\u001b[38;5;241m=\u001b[39mData[i\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m0\u001b[39m]:i\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mKernel[\u001b[38;5;241m0\u001b[39m],j\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m1\u001b[39m]:j\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mKernel[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m             \u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39mData[i\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m0\u001b[39m]:i\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39mKernel[\u001b[38;5;241m0\u001b[39m],j\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m1\u001b[39m]:j\u001b[38;5;241m*\u001b[39mStride[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39mKernel[\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.005\n",
    "for tt in range(1000):\n",
    "    C1=convnet2d(Data=Data1,Kernel=Kernel1,bias=bias1,Padding=Padding1,Stride=Stride1)\n",
    "    print(C1.shape)\n",
    "    P1=poolnet_2d(C1,Kernel=(2,2),mode='mean',Padding=(0,0),Stride=(2,2))\n",
    "    print(P1.shape)\n",
    "    C2=convnet2d(P1,Kernel2,bias2,Padding=(0,0),Stride=(1,1))\n",
    "    print(C2.shape)\n",
    "    P2=poolnet_2d(C2,Kernel=(2,2),mode='mean',Padding=(0,0),Stride=(2,2))\n",
    "    print(P2.shape)\n",
    "    Y=torch.zeros((P2.shape[0],P2.shape[1]*P2.shape[2]*P2.shape[3]))\n",
    "    for i in range(P2.shape[0]):\n",
    "        Y[i,:]=P2[i,:,:,:].reshape(1,-1)\n",
    "    Y1=1/(1+torch.exp(-torch.mm(Y,weight1)))\n",
    "    Y2=1/(1+torch.exp(-torch.mm(Y1,weight2)))\n",
    "    #Y3=1/(1+torch.exp(-torch.mm(Y2,weight3)))\n",
    "    Y3=torch.exp(torch.mm(Y2,weight3))/(torch.exp(torch.mm(Y2,weight3))).sum(axis=1).reshape(Y2.shape[0],1)\n",
    "    print(Y3[0,:])\n",
    "    #上面输出的是全链接层的结果\n",
    "    #我们思考一下损失函数怎么定义，从结果上来看是概率分布的交叉熵，从实际上来看应该是最大似然函数。\n",
    "    loss=(-1*Label1*torch.log(Y3)).sum()\n",
    "    loss.backward()\n",
    "    Kernel1.data=Kernel1.data-lr*Kernel1.grad.data\n",
    "    bias1.data=bias1.data-lr*bias1.grad.data\n",
    "    Kernel2.data=Kernel2.data-lr*Kernel2.grad.data\n",
    "    bias2.data=bias2.data-lr*bias2.grad.data\n",
    "    weight1.data=weight1.data-lr*weight1.grad.data\n",
    "    weight2.data=weight2.data-lr*weight2.grad.data\n",
    "    weight3.data=weight3.data-lr*weight3.grad.data\n",
    "    Kernel1.grad.data.zero_()\n",
    "    bias1.grad.data.zero_()\n",
    "    Kernel2.grad.data.zero_()\n",
    "    bias2.grad.data.zero_()\n",
    "    weight1.grad.data.zero_()\n",
    "    weight2.grad.data.zero_()\n",
    "    weight3.grad.data.zero_()\n",
    "    print(loss,Y3[0,:],Label1[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c272f7-2112-410d-bbd0-d5315cf7f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0880, 0.0944, 0.0743, 0.0463, 0.2468, 0.0896, 0.0553, 0.0722, 0.1455,\n",
      "         0.0876],\n",
      "        [0.0641, 0.1485, 0.2121, 0.0522, 0.0283, 0.1448, 0.0353, 0.2320, 0.0357,\n",
      "         0.0470],\n",
      "        [0.2198, 0.0590, 0.0744, 0.0710, 0.1931, 0.0417, 0.0511, 0.1130, 0.0812,\n",
      "         0.0956],\n",
      "        [0.1250, 0.0590, 0.0741, 0.0945, 0.1652, 0.0315, 0.0904, 0.1518, 0.1689,\n",
      "         0.0396],\n",
      "        [0.1451, 0.4192, 0.0386, 0.0198, 0.1165, 0.0235, 0.0995, 0.0248, 0.0211,\n",
      "         0.0918],\n",
      "        [0.0186, 0.0399, 0.1666, 0.0731, 0.2361, 0.0813, 0.0308, 0.0423, 0.1649,\n",
      "         0.1464],\n",
      "        [0.1456, 0.0425, 0.4062, 0.0518, 0.0967, 0.0667, 0.0349, 0.0766, 0.0221,\n",
      "         0.0568],\n",
      "        [0.0339, 0.1452, 0.2330, 0.0500, 0.0872, 0.1240, 0.0237, 0.0524, 0.0931,\n",
      "         0.1577],\n",
      "        [0.3463, 0.0425, 0.0813, 0.1099, 0.0580, 0.0418, 0.0685, 0.0521, 0.0562,\n",
      "         0.1432],\n",
      "        [0.1710, 0.0468, 0.0685, 0.3048, 0.0370, 0.0451, 0.1487, 0.0430, 0.1041,\n",
      "         0.0309]], grad_fn=<DivBackward0>) \n",
      " tensor([[0.0835, 0.0828, 0.0829, 0.0370, 0.2457, 0.0858, 0.0649, 0.0610, 0.1569,\n",
      "         0.0995],\n",
      "        [0.0717, 0.1649, 0.2175, 0.0514, 0.0129, 0.1458, 0.0254, 0.2547, 0.0264,\n",
      "         0.0293],\n",
      "        [0.2208, 0.0468, 0.0673, 0.0594, 0.1954, 0.0363, 0.0760, 0.1210, 0.0861,\n",
      "         0.0909],\n",
      "        [0.1221, 0.0573, 0.0587, 0.1118, 0.1704, 0.0321, 0.1017, 0.1623, 0.1658,\n",
      "         0.0176],\n",
      "        [0.1522, 0.4274, 0.0409, 0.0095, 0.1310, 0.0239, 0.1097, 0.0138, 0.0089,\n",
      "         0.0826],\n",
      "        [0.0100, 0.0450, 0.1766, 0.0717, 0.2350, 0.0751, 0.0098, 0.0189, 0.1788,\n",
      "         0.1792],\n",
      "        [0.1464, 0.0368, 0.4047, 0.0598, 0.0956, 0.0731, 0.0193, 0.0765, 0.0165,\n",
      "         0.0713],\n",
      "        [0.0310, 0.1438, 0.2350, 0.0475, 0.0858, 0.1226, 0.0202, 0.0540, 0.0971,\n",
      "         0.1631],\n",
      "        [0.3520, 0.0491, 0.0726, 0.1224, 0.0558, 0.0451, 0.0432, 0.0560, 0.0500,\n",
      "         0.1538],\n",
      "        [0.1674, 0.0415, 0.0745, 0.3021, 0.0388, 0.0509, 0.1673, 0.0410, 0.1065,\n",
      "         0.0100]])\n"
     ]
    }
   ],
   "source": [
    "print(Y3,'\\n',Label1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bae47-bb89-4be9-9486-6245e4300ab0",
   "metadata": {},
   "source": [
    "# backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad4425-1e43-40b9-aaca-35a24c9a967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#二维卷积无padding\n",
    "def corr2d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),Stride=(1,1))\n",
    "#二维卷积有padding\n",
    "#def corr2d_pad(Data=(a,b),Kernel=(c,d),Padding=(e,f),Stride=(g,h)):\n",
    "def corr2d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr2d_pad(torch.tensor([[1,2,3],[4,5,6],[5,6,7]]),torch.tensor([[1,2],[2,3]]),(1,1),(1,1))\n",
    "#三维卷积无padding\n",
    "def corr3d(Data,Kernel,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Stride=(1,1,1))\n",
    "#三维卷积有padding\n",
    "def corr3d_pad(Data,Kernel,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel.shape[0])//(Stride[0])+1,(Data.shape[1]-Kernel.shape[1])//(Stride[1])+1,(Data.shape[2]-Kernel.shape[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                Y[i,j,k]=(Data[i*Stride[0]:i*Stride[0]+Kernel.shape[0],j*Stride[1]:j*Stride[1]+Kernel.shape[1],k*Stride[2]:k*Stride[2]+Kernel.shape[2]]*Kernel).sum()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#corr3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=torch.tensor([[[1,2],[1,1]],[[1,-1],[-1,2]]]),Padding=(0,0,0),Stride=(1,1,1))\n",
    "####################################################\n",
    "#池化\n",
    "#二维池化无padding\n",
    "#def pool2d(Data,Mode='max,'avg'):\n",
    "def pool2d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d(torch.tensor([[1.,2,3],[4,5,6],[5,6,7.]]),(2,3),'mean',Stride=(1,1))\n",
    "#二维池化有padding\n",
    "def pool2d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1])),Data,torch.zeros((Padding[0],Data.shape[1]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1])),Data,torch.zeros((Data.shape[0],Padding[1]))),axis=1)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode=='max':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].max()\n",
    "            elif mode=='mean':\n",
    "                Y[i,j]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool2d_pad(torch.tensor([[1.,2,3],[4,5,6],[5,6,7]]),(2,2),'mean',(1,1),(1,1))\n",
    "#三维池化无padding\n",
    "def pool3d(Data,Kernel,mode,Stride):\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Stride=(1,1,1))\n",
    "#三维池化有padding\n",
    "def pool3d_pad(Data,Kernel,mode,Padding,Stride):\n",
    "    Data=torch.concatenate((torch.zeros((Padding[0],Data.shape[1],Data.shape[2])),Data,torch.zeros((Padding[0],Data.shape[1],Data.shape[2]))),axis=0)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Padding[1],Data.shape[2])),Data,torch.zeros((Data.shape[0],Padding[1],Data.shape[2]))),axis=1)\n",
    "    Data=torch.concatenate((torch.zeros((Data.shape[0],Data.shape[1],Padding[2])),Data,torch.zeros((Data.shape[0],Data.shape[1],Padding[2]))),axis=2)\n",
    "    Y=torch.zeros(((Data.shape[0]-Kernel[0])//(Stride[0])+1,(Data.shape[1]-Kernel[1])//(Stride[1])+1,(Data.shape[2]-Kernel[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            for k in range(Y.shape[2]):\n",
    "                if mode=='max':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].max()\n",
    "                elif mode=='mean':\n",
    "                    Y[i,j,k]=Data[i*Stride[0]:i*Stride[0]+Kernel[0],j*Stride[1]:j*Stride[1]+Kernel[1],k*Stride[2]:k*Stride[2]+Kernel[2]].mean()\n",
    "    return Y\n",
    "# 测试案例\n",
    "#pool3d_pad(Data=torch.tensor([[[1,2,3],[4,5,6]],[[7,8,9],[1,2,3]]]),Kernel=(2,2,2),mode='max',Padding=(0,0,0),Stride=(1,1,1))\n",
    "#二维测试\n",
    "#Data=torch.randn(5,5)\n",
    "#Kernel=torch.randn(3,3)\n",
    "#Stride=(1,1)\n",
    "#Padding=(1,1)\n",
    "#print(Data,Kernel,Stride)\n",
    "#print((Data[1:4,1:4]*Kernel).sum())\n",
    "#Y=corr2d_pad(Data,Kernel,Stride,Padding)\n",
    "#print(Y)\n",
    "#Z=pool2d_pad(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#三维测试\n",
    "#Data=torch.randn(5,5,5)\n",
    "#Kernel=torch.randn(3,3,3)\n",
    "#Stride=(1,1,1)\n",
    "#Padding=(1,1,1)\n",
    "#print(Data,Kernel,Padding,Stride)\n",
    "#print((Data[1:4,1:4,2:5]*Kernel).sum())\n",
    "#Y=corr3d_pad(Data=Data,Kernel=Kernel,Padding=Padding,Stride=Stride)\n",
    "#print(Y)\n",
    "#Z=pool3d_pad(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53579a2b-4c8b-4f91-90f3-711fd720af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积层操作无padding\n",
    "#下面是二维样本特征时多样本多输出的卷积层\n",
    "def convnet_2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1))\n",
    "    #第几个样本\n",
    "    for i in range(Y.shape[0]):\n",
    "        #第几个输出内核\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr2d_pad(Data[i,:,:].reshape(Data.shape[1:]),Kernel[j,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:]+=bias[j]        \n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#定义完整的二维样本卷积层\n",
    "#def conv_2d(Data=(样本数,输入通道数,特征),Kernel=(输出通道数,输入通道数,二维卷积核),bias=(输出通道数,1),Padding=(二维扩充尺寸),Stride=(二维步进尺寸))->(样本数,输出通道数,卷积结果)\n",
    "def convnet2d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[2]-Kernel.shape[2]+2*Padding[0])//Stride[0]+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[1])//Stride[1]+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),(0,Padding[0],Padding[1]),(1,Stride[0],Stride[1])).reshape(Y.shape[2],Y.shape[3])\n",
    "            Y[i,j,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#每个(输出通道,输入通道)组合都有一个偏置还是每个输出通道才有偏置，还是每个输入通道有偏置？还是每个卷积核都有一个偏置？\n",
    "#前面的输出矩阵的尺寸容易理解，找几个例子推算一下就清楚了，\n",
    "#下面是三维样本特征时多样本多输出的卷积层\n",
    "def convnet_3d(Data,Kernel,bias,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Kernel.shape[0],(Data.shape[1]-Kernel.shape[1]+2*Padding[0])//(Stride[0])+1,(Data.shape[2]-Kernel.shape[2]+2*Padding[1])//(Stride[1])+1,(Data.shape[3]-Kernel.shape[3]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=corr3d_pad(Data[i,:,:,:].reshape(Data.shape[1:]),Kernel[j,:,:,:].reshape(Kernel.shape[1:]),Padding,Stride)\n",
    "            Y[i,j,:,:,:]+=bias[j]\n",
    "    Y=1/(1+torch.exp(-Y))\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#下面是二维样本特征多样本多输出的汇聚层。\n",
    "def poolnet_2d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:]=pool2d_pad(Data[i,j,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_2d(torch.randn(1,7,7),Kernel,bias,Padding=(1,1),Stride=(1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_2d(Y,Kernel=(3,3),mode='max',Padding=(1,1),Stride=(1,1))\n",
    "#print(Z)\n",
    "#下面是三维样本特征多样本多输出的汇聚层\n",
    "def poolnet_3d(Data,Kernel,mode,Padding,Stride):\n",
    "    Y=torch.zeros((Data.shape[0],Data.shape[1],(Data.shape[2]-Kernel[0]+2*Padding[0])//(Stride[0])+1,(Data.shape[3]-Kernel[1]+2*Padding[1])//(Stride[1])+1,(Data.shape[4]-Kernel[2]+2*Padding[2])//(Stride[2])+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j,:,:,:]=pool3d_pad(Data[i,j,:,:,:].reshape(Data.shape[2:]),Kernel,mode,Padding,Stride)\n",
    "    return Y\n",
    "#测试\n",
    "#Kernel=torch.randn((4,3,3,3),requires_grad=True)\n",
    "#bias=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "#Y=convnet_3d(torch.randn(1,7,7,7),Kernel,bias,Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Y)\n",
    "#Z=poolnet_3d(Y,Kernel=(3,3,3),mode='max',Padding=(1,1,1),Stride=(1,1,1))\n",
    "#print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aeebec-3b02-4631-93ad-bf31f662d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def convnet_2d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_2d(Data,Kernel,mode,Padding,Stride)\n",
    "#def convnet_3d(Data,Kernel,bias,Padding,Stride)\n",
    "#def poolnet_3d(Data,Kernel,mode,Padding,Stride)\n",
    "Data1=torch.randn((4,28,28))\n",
    "Kernel1=torch.randn((6,5,5),requires_grad=True)\n",
    "bias1=torch.randn((Kernel.shape[0],1),requires_grad=True)\n",
    "Padding1=(2,2)\n",
    "Stride1=(1,1)\n",
    "C1=convnet_2d(Data=Data1,Kernel=Kernel1,bias=bias1,Padding=Padding1,Stride=Stride1)\n",
    "print(C1.shape)\n",
    "P1=poolnet_2d(C1,Kernel=(2,2),mode='mean',Padding=(0,0),Stride=(2,2))\n",
    "print(P1.shape)\n",
    "Kernel2=torch.randn((16,6,5,5),requires_grad=True)\n",
    "bias2=torch.randn((Kernel2.shape[0],1),requires_grad=True)\n",
    "C2=convnet_3d(P1,Kernel2,bias2,Padding=(0,0,0),Stride=(1,1,1))\n",
    "print(C2.shape)\n",
    "P2=poolnet_3d(C2,Kernel=(1,2,2),mode='mean',Padding=(0,0,0),Stride=(2,2,2))\n",
    "print(P2.shape)\n",
    "Y=torch.zeros((P2.shape[0],P2.shape[1]*P2.shape[2]*P2.shape[3]*P2.shape[4]))\n",
    "for i in range(P2.shape[0]):\n",
    "    Y[i,:]=P2[i,:,:,:,:].reshape(1,-1)\n",
    "\n",
    "weight1=torch.randn((Y.shape[1],120),requires_grad=True)\n",
    "Y1=1/(1+torch.exp(-torch.mm(Y,weight1)))\n",
    "weight2=torch.randn((Y1.shape[1],84),requires_grad=True)\n",
    "Y2=1/(1+torch.exp(-torch.mm(Y1,weight2)))\n",
    "weight3=torch.randn((Y2.shape[1],10),requires_grad=True)\n",
    "Y3=1/(1+torch.exp(-torch.mm(Y2,weight3)))\n",
    "print(Y3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
